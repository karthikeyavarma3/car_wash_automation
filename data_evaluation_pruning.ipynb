{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial dataset presented a few challenges that needed to be addressed. \n",
    "1) the images in the dataset were of different sizes, which could potentially affect the model's performance. \n",
    "2) some images were in GIF format, which needed to be eliminated. \n",
    "3) there were images in the dataset where the car logo was not clearly visible, making them less useful for the brand prediction task. \n",
    "4) Additionally, images depicting cars in side view posed a challenge since the frontal view with the logo was more informative.\n",
    "5) the images from one particular class are repeated in other classes, this would affect the final model's performance in predicting the car logos.\n",
    "6) Lastly, the dataset was not equally balanced among the car brands, which could introduce bias in the model's predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "In this task, the goal was to automate the data preprocessing and eliminate unnecessary data that would not contribute to the final model's ability to predict the car brand accurately. \n",
    "\n",
    "To achieve this, a model was developed to prune the dataset, resulting in a cleaner and more focused dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "from keras.layers import MaxPooling2D, Conv2D, Dropout,Flatten\n",
    "from keras.models import Model \n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r'C:\\Projects\\e-AUTO\\eAuto_photos\\automation_prune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['junk' , 'correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\automation_prune\\junk\\frontfacingHyundaicar362.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\automation_prune\\junk\\frontfacingNissancar503.gif\n"
     ]
    }
   ],
   "source": [
    "for category in classes:\n",
    "    path = os.path.join(dir , category)\n",
    "    label = classes.index(category)\n",
    "    \n",
    "    \n",
    "\n",
    "    for img in os.listdir(path):\n",
    "        image = cv2.imread(os.path.join(path , img))\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path , img))\n",
    "            if image is not None:\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                img_resize = cv2.resize(image_rgb , (128,128))\n",
    "                \n",
    "            else:\n",
    "                print(f\"Error loading image: {os.path.join(path, img)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {os.path.join(path, img)}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "        \n",
    "        training_data.append([img_resize, label])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVING THE IMAGES THAT END WITH .gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = [r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Hyundai\\frontfacingHyundaicar327.gif' , r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Hyundai\\frontfacingHyundaicar339.gif' , r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Hyundai\\frontfacingHyundaicar362.gif' , r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Nissan\\frontfacingNissancar123.gif',r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Nissan\\frontfacingNissancar463.gif',r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Nissan\\frontfacingNissancar503.gif',r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Renault\\frontfacingRenaultcar458.gif',r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Suzuki\\frontfacingsuzukicar527.gif',r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Tata\\frontfacingTatamotorscar407.gif' , r'C:\\Projects\\e-AUTO\\eAuto_photos\\original_set\\Toyota\\frontfacingToyotacar359.gif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already removed\n",
      "Already removed\n",
      "Already removed\n",
      "Already removed\n",
      "Already removed\n",
      "Already removed\n",
      "Already removed\n"
     ]
    }
   ],
   "source": [
    "for img in gif:\n",
    "    try:\n",
    "\n",
    "        os.remove(img)\n",
    "    except FileNotFoundError:\n",
    "        print('Already removed')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features , label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\n",
    "    filepath = 'best_model.v2',\n",
    "    monitor = 'val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode = 'max',\n",
    "    \n",
    "    \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_accuracy',\n",
    "#     patience=3,\n",
    "#     mode='max',\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32 , kernel_size=(3,3) , activation='relu' , input_shape = (128,128,3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    # Conv2D(32 , kernel_size=(3,3) , activation='relu'),\n",
    "    # MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128 , activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    \n",
    "    Dense(1 , activation='sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.4038 - accuracy: 0.5228\n",
      "Epoch 1: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 7s 383ms/step - loss: 2.4038 - accuracy: 0.5228 - val_loss: 0.5544 - val_accuracy: 0.7714\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.6182\n",
      "Epoch 2: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 334ms/step - loss: 0.7036 - accuracy: 0.6182 - val_loss: 0.5223 - val_accuracy: 0.8000\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.7688\n",
      "Epoch 3: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.4943 - accuracy: 0.7688 - val_loss: 0.4889 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8441\n",
      "Epoch 4: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 351ms/step - loss: 0.3984 - accuracy: 0.8441 - val_loss: 0.3931 - val_accuracy: 0.8857\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.8908\n",
      "Epoch 5: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 6s 373ms/step - loss: 0.2848 - accuracy: 0.8908 - val_loss: 0.3662 - val_accuracy: 0.8857\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9343\n",
      "Epoch 6: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 343ms/step - loss: 0.2022 - accuracy: 0.9343 - val_loss: 0.3231 - val_accuracy: 0.8857\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9565\n",
      "Epoch 7: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 344ms/step - loss: 0.1315 - accuracy: 0.9565 - val_loss: 0.3261 - val_accuracy: 0.8762\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9777\n",
      "Epoch 8: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 341ms/step - loss: 0.0974 - accuracy: 0.9777 - val_loss: 0.3514 - val_accuracy: 0.8762\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9873\n",
      "Epoch 9: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 340ms/step - loss: 0.0610 - accuracy: 0.9873 - val_loss: 0.3828 - val_accuracy: 0.8762\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9936\n",
      "Epoch 10: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 356ms/step - loss: 0.0357 - accuracy: 0.9936 - val_loss: 0.4860 - val_accuracy: 0.8381\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9936\n",
      "Epoch 11: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 339ms/step - loss: 0.0360 - accuracy: 0.9936 - val_loss: 0.5443 - val_accuracy: 0.8095\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9968\n",
      "Epoch 12: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 340ms/step - loss: 0.0216 - accuracy: 0.9968 - val_loss: 0.5782 - val_accuracy: 0.8286\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9968\n",
      "Epoch 13: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 350ms/step - loss: 0.0264 - accuracy: 0.9968 - val_loss: 0.4823 - val_accuracy: 0.8476\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9979\n",
      "Epoch 14: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 344ms/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.5473 - val_accuracy: 0.8667\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9968\n",
      "Epoch 15: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 342ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.5588 - val_accuracy: 0.8857\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9968\n",
      "Epoch 16: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 355ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.5793 - val_accuracy: 0.8667\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9979\n",
      "Epoch 17: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 360ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.6257 - val_accuracy: 0.8762\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 349ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.8571\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9968\n",
      "Epoch 19: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 352ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.6719 - val_accuracy: 0.8571\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9989\n",
      "Epoch 20: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 341ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.6346 - val_accuracy: 0.8952\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 21: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 6s 371ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.6663 - val_accuracy: 0.8762\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9989\n",
      "Epoch 22: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 342ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.7791 - val_accuracy: 0.8476\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9979\n",
      "Epoch 23: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 344ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.7228 - val_accuracy: 0.8476\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 24: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 350ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.6855 - val_accuracy: 0.8476\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9989\n",
      "Epoch 25: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 337ms/step - loss: 0.0075 - accuracy: 0.9989 - val_loss: 0.8356 - val_accuracy: 0.8476\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 26: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 335ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.7413 - val_accuracy: 0.8762\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9989\n",
      "Epoch 27: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.7848 - val_accuracy: 0.8571\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9958\n",
      "Epoch 28: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 354ms/step - loss: 0.0077 - accuracy: 0.9958 - val_loss: 0.9088 - val_accuracy: 0.8381\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 29: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 360ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.8837 - val_accuracy: 0.8095\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 30: val_accuracy did not improve from 0.91429\n",
      "15/15 [==============================] - 5s 345ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.8271 - val_accuracy: 0.8762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aee8acbdc0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( X, Y , epochs = 30 , validation_split = 0.1  , batch_size = 64 , callbacks=[check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = r'C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Ford' , 'Honday' , 'Hyundai' , 'Nissan' , 'Renault' , 'Suzuki','Tata' , 'Toyota' , 'Volkswagen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Hyundai\\frontfacingHyundaicar327.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Hyundai\\frontfacingHyundaicar339.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Hyundai\\frontfacingHyundaicar362.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Nissan\\frontfacingNissancar123.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Nissan\\frontfacingNissancar463.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Nissan\\frontfacingNissancar503.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Renault\\frontfacingRenaultcar458.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Suzuki\\frontfacingsuzukicar527.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Tata\\frontfacingTatamotorscar407.gif\n",
      "Error loading image: C:\\Projects\\e-AUTO\\eAuto_photos\\eAuto_photos\\photos\\Toyota\\frontfacingToyotacar359.gif\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    path = os.path.join(p_dir , category)\n",
    "   \n",
    "    for img in os.listdir(path):\n",
    "        \n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path , img))\n",
    "            if image is not None:\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                img_resize = cv2.resize(image_rgb , (128,128))\n",
    "                \n",
    "            else:\n",
    "                print(f\"Error loading image: {os.path.join(path, img)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {os.path.join(path, img)}\")\n",
    "            print(f\"Error message: {str(e)}\")\n",
    "            continue\n",
    "        try:\n",
    "            \n",
    "\n",
    "            img_resize = img_resize/255\n",
    "            img_resize = np.expand_dims(img_resize , axis=0)\n",
    "            prediction = model.predict(img_resize)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if prediction[0]<0.3:\n",
    "            os.remove(os.path.join(path , img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no_of_images in the class Ford : 268\n",
      "The no_of_images in the class Honday : 19\n",
      "The no_of_images in the class Hyundai : 272\n",
      "The no_of_images in the class Nissan : 230\n",
      "The no_of_images in the class Renault : 321\n",
      "The no_of_images in the class Suzuki : 233\n",
      "The no_of_images in the class Tata : 191\n",
      "The no_of_images in the class Toyota : 268\n",
      "The no_of_images in the class Volkswagen : 153\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "\n",
    "    lst = os.listdir(os.path.join(p_dir , category))\n",
    "    print(f\"The no_of_images in the class {category} : {len(lst)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying this model to the dataset, the non-relevant images were pruned, resulting in a more focused dataset for further analysis.\n",
    "So, the updated no of images in each class after pruning are as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->After the initial automated data pruning process, some manual editing was performed to refine the dataset even further. \n",
    "\n",
    "-->Some images required manual cropping and zooming to focus specifically on the car logo, effectively reducing the noise in the      data and improving the model's ability to learn the distinguishing features of each brand. \n",
    "\n",
    "-->Additionally, a few images that were deemed irrelevant or redundant were removed from the dataset during this manual editing phase. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no_of_images in the class Ford : 240\n",
      "The no_of_images in the class Honday : 19\n",
      "The no_of_images in the class Hyundai : 262\n",
      "The no_of_images in the class Nissan : 223\n",
      "The no_of_images in the class Renault : 307\n",
      "The no_of_images in the class Suzuki : 185\n",
      "The no_of_images in the class Tata : 160\n",
      "The no_of_images in the class Toyota : 200\n",
      "The no_of_images in the class Volkswagen : 152\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "\n",
    "    lst = os.listdir(os.path.join(p_dir , category))\n",
    "    print(f\"The no_of_images in the class {category} : {len(lst)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through a combination of automated data pruning and manual editing, the dataset for car brand prediction was effectively cleaned and refined. \n",
    "\n",
    "The challenges presented by differently sized images, GIF format, unclear logo visibility, side view images, and dataset imbalance were addressed, resulting in a more balanced, informative, and cleaner dataset. \n",
    "\n",
    "This prepared dataset is expected to contribute positively to the training and performance of the final model, enabling accurate predictions of car brands based on their logos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After this, we have very small dataset, having only few images in each class. Hence, we can augment data to some 1000 images in each class with different shear range, brightness, rotation at different angles, flips etc.\n",
    "\n",
    "*  This would create a sufficient dataset for the final_model to predict the car logo.\n",
    "\n",
    "*  And also, standardize the images to same size and normalize the pixels values so the training would happen in a smooth way, reaching the global maxima for this problem statement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
